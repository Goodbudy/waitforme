it's not that i have alzheimers but i will forget what i'm meant to be doing

Step 1: get all turtlebot and map stuff working 
Step 2: make some code so that when i launch turtlebot it will automagically localise.
Step 3: give it some intelligence so it can figure out what is what (use opencv feature recognition)
Step 4: get it to figure out where the other turtlebot is and how it's moving (more coding)
Step 5: Can use libraries but to use deep learning to predict what objects are. use SVM. https://scikit-learn.org/stable/modules/svm.html
this will be a neural network, which i have fed data so it can hopefully recognise differnet objects


New To Do 
1. Object recognition - recognise objects and publish positions and size. (Issy RS1 sprint 3.6)
2. Localisation - be able to publish a point to the robot
3. Localisation2 - localise from lidar data (Issy RS1 code?)
4. get it to figure out where the other turtlebot is and how it's moving (more coding/ OpenCV?)
5. Can use libraries but to use deep learning to predict what objects are. use SVM. https://scikit-learn.org/stable/modules/svm.html
this will be a neural network, which i have fed data so it can hopefully recognise differnet objects

Note: OpenCV is only useful when using camera data, not for Lidar, hence not used for credit. Maybe distinction/HD?


opencv needs to be installed for certain things to working

ros2 localisation nodes need to be installed with this
sudo apt install ros-humble-robot-localization

for camera maybe this
sudo apt install ros-humble-image-transport ros-humble-compressed-image-transport
